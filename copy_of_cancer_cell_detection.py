# -*- coding: utf-8 -*-
"""Copy of cancer cell detection.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1FJsUWDytFfAFArB4Za4KmYnSQb_9OBAz
"""

import seaborn as sns
import matplotlib.pyplot as plt
import numpy as np
from sklearn.model_selection import train_test_split
import os, cv2
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, Flatten, Dense, MaxPool2D ,Dropout

import pandas as pd
data = pd.read_csv('hmnist_28_28_RGB.csv')

y = data['label']
x = data.drop(columns = ['label'])

tabular_data = pd.read_csv('HAM10000_metadata.csv')
tabular_data.head()

tabular_data.shape

classes = {4: ('nv', ' melanocytic nevi'), 6: ('mel', 'melanoma'),
           2 :('bkl', 'benign keratosis-like lesions'), 1:('bcc' , ' basal cell carcinoma'),
           5: ('vasc', ' pyogenic granulomas and hemorrhage'), 0: ('akiec', 'Actinic keratoses and intraepithelial carcinomae'),  3: ('df', 'dermatofibroma')}

sns.countplot(x = 'dx', data = tabular_data)
plt.xlabel('Types of cancer ', size=12)
plt.ylabel('Frequency', size=12)
plt.title('Distribution ', size=16)

bar, ax = plt.subplots(figsize = (10,10))
plt.pie(tabular_data['sex'].value_counts(), labels = tabular_data['sex'].value_counts().index, autopct="%.1f%%")
plt.title('Gender of paitents', size=16)

tabular_data['localization'].value_counts().to_frame()

tabular_data['dx'].value_counts()

value = tabular_data[['localization', 'sex']].value_counts().to_frame()
value.reset_index(level=[1,0 ], inplace=True)
temp = value.rename(columns = {'localization':'location', 0: 'count'})

bar, ax = plt.subplots(figsize = (12, 12))
sns.barplot(x = 'location',  y='count', hue = 'sex', data = temp)
plt.title('Location of disease over Gender', size = 16)
plt.xlabel('Disease', size=12)
plt.ylabel('Frequency/Count', size=12)
plt.xticks(rotation = 90)

x = np.array(x).reshape(-1,28,28,3)
print('Shape of X :',x.shape)

x = (x-np.mean(x))/np.std(x)
X_train, X_test, Y_train, Y_test = train_test_split(x,y, test_size=0.2, random_state=1)
Y_train

model = Sequential()
model.add(Conv2D(16, kernel_size=(3, 3), input_shape=(28, 28, 3), activation='relu', padding='same'))
model.add(Conv2D(32, kernel_size=(3, 3), activation='relu'))
model.add(MaxPool2D(pool_size=(2, 2)))
model.add(Dropout(0.5))  # Added dropout layer

model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', padding='same'))
model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))
model.add(MaxPool2D(pool_size=(2, 2), padding='same'))
model.add(Dropout(0.5))  # Added dropout layer

model.add(Flatten())
model.add(Dense(64, activation='relu'))
model.add(Dropout(0.4))  # Added dropout layer
model.add(Dense(32, activation='relu'))
model.add(Dropout(0.4))  # Added dropout layer
model.add(Dense(7, activation='softmax'))
model.summary()

callback = tf.keras.callbacks.ModelCheckpoint(filepath='my_model6.h5',
                                                  monitor='val_acc', mode='max',
                                                 verbose=1)

from tensorflow.keras.metrics import Precision, Recall, AUC
from tensorflow.keras.optimizers import Adam

from tensorflow.keras.metrics import (
    SparseCategoricalAccuracy,
    SparseTopKCategoricalAccuracy,
    SparseCategoricalCrossentropy,
)
num_classes = 7  # Replace this with the number of classes in your dataset
optimizer = Adam(learning_rate=0.001)

model.compile(
    loss="sparse_categorical_crossentropy",
    optimizer=optimizer,
    metrics=["accuracy"],
)

history = model.fit(
    X_train,
    Y_train,
    validation_split=0.20,
    batch_size=64,
    epochs=50,
    callbacks=[callback],
)

import numpy as np
from sklearn.metrics import (
    classification_report,
    precision_recall_fscore_support,
    roc_auc_score,
)

# Get the predictions for the test set
Y_pred_probs = model.predict(X_test)
Y_pred_labels = np.argmax(Y_pred_probs, axis=1)

# Calculate precision, recall, and F1-score
precision, recall, _, _ = precision_recall_fscore_support(Y_test, Y_pred_labels, average="macro")

# Calculate the AUC (macro-average)
roc_auc = roc_auc_score(Y_test, Y_pred_probs, multi_class="ovr", average="macro")

# Print the results
print("Precision:", precision)
print("Recall:", recall)
print("AUC:", roc_auc)

# Optional: Print the detailed classification report
print(classification_report(Y_test, Y_pred_labels))

